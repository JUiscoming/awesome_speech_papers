# awesome_speech_papers
awesome_speech_papers


# End-to-End Speech Recognition (음성 인식) 
|year|conference|research organization|title|model|link|
|--|--|--|------|---|--|
|2015|ICASSP|Google|Listen, Attend and Spell|Seq2Seq|[arxiv link](https://arxiv.org/pdf/1508.01211)|
 
<br>
 
# End-to-End Speech Synthesis (음성 합성)

<br>

# End-to-End Spoken Language Understanding (음성 언어 이해)

<br>

# Self-Supervised(or Semi-Supervised) Learning for Speech 
|year|conference|research organization|title|link|
|--|--|--|------|--|
|2019|-|Facebook AI Research (FAIR)|wav2vec: Unsupervised Pre-training for Speech Recognition|[arxiv link](https://arxiv.org/pdf/1904.05862)|
|2019|ICLR|Facebook AI Research (FAIR)|vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations|[arxiv link](https://arxiv.org/pdf/1910.05453)|
|2020|-|Facebook AI Research (FAIR)|wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations|[arxiv link](https://arxiv.org/pdf/2006.11477)|
|2019|-|Deepmind|Learning robust and multilingual speech representations|[arxiv link](https://arxiv.org/pdf/2001.11128)|
|-|-|Deepmind|Self-Supervised Representations Improve End-to-End Speech Translation|[arxiv link](https://arxiv.org/pdf/1508.01211)|
|-|-|Deepmind|Unsupervised Pretraining Transfers Well Across Languages|[arxiv link](https://arxiv.org/pdf/1508.01211)|
|-|-|Deepmind|Learning Problem-agnostic Speech Representations from Multiple Self-supervised Tasks|[arxiv link](https://arxiv.org/pdf/1508.01211)|
|-|-|Deepmind|Learning robust and multilingual speech representations|[arxiv link](https://arxiv.org/pdf/1508.01211)|
|-|-|Deepmind|Problem-Agnostic Speech Embeddings for Multi-Speaker Text-to-Speech with SampleRNN|[arxiv link](https://arxiv.org/pdf/1508.01211)|
|2020|-|MIT CSAIL|SEMI-SUPERVISED SPEECH-LANGUAGE JOINT PRE- TRAINING FOR SPOKEN LANGUAGE UNDERSTANDING|[arxiv link](https://arxiv.org/pdf/2010.02295)|
