# awesome_speech_papers
awesome_speech_papers


# Speech Recognition (음성 인식) 
|year|conference|research organization|title|model|link|
|--|--|--|------|---|--|
|2015|ICASSP|Google|Listen, Attend and Spell|Seq2Seq|[arxiv link](https://arxiv.org/pdf/1508.01211)|
 
# Speech Synthesis (음성 합성)

# Spoken Language Understanding (음성 언어 이해)

# Self-Supervised(or Semi-Supervised) Learning for Speech 
|year|conference|research organization|title|link|
|--|--|--|------|--|
|2015|ICASSP|Google|wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations|[arxiv link](https://arxiv.org/pdf/1508.01211)|
|2015|ICASSP|Deepmind|Learning robust and multilingual speech representations|[arxiv link](https://arxiv.org/pdf/1508.01211)|
|2015|ICASSP|Deepmind|Self-Supervised Representations Improve End-to-End Speech Translation|[arxiv link](https://arxiv.org/pdf/1508.01211)|
|2015|ICASSP|Deepmind|Unsupervised Pretraining Transfers Well Across Languages|[arxiv link](https://arxiv.org/pdf/1508.01211)|
|2015|ICASSP|Deepmind|Learning Problem-agnostic Speech Representations from Multiple Self-supervised Tasks|[arxiv link](https://arxiv.org/pdf/1508.01211)|
|2015|ICASSP|Deepmind|Learning robust and multilingual speech representations|[arxiv link](https://arxiv.org/pdf/1508.01211)|
|2015|ICASSP|Deepmind|Problem-Agnostic Speech Embeddings for Multi-Speaker Text-to-Speech with SampleRNN|[arxiv link](https://arxiv.org/pdf/1508.01211)|
|2020|-|MIT CSAIL|SEMI-SUPERVISED SPEECH-LANGUAGE JOINT PRE- TRAINING FOR SPOKEN LANGUAGE UNDERSTANDING|[arxiv link](https://arxiv.org/pdf/2010.02295)|
